<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>lakota.series API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lakota.series</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from numpy import ascontiguousarray, dtype, issubdtype

from .batch import Batch
from .changelog import phi
from .commit import Commit
from .frame import Frame
from .utils import Closed, Interval, Pool, hashed_path, settings

__all__ = [&#34;Series&#34;, &#34;KVSeries&#34;]


def intersect(revision, start, stop):
    ok_start = not stop or revision[&#34;start&#34;][: len(stop)] &lt;= stop
    ok_stop = not start or revision[&#34;stop&#34;][: len(start)] &gt;= start
    if not (ok_start and ok_stop):
        return None
    # return reduced range
    max_start = max(revision[&#34;start&#34;], start)
    min_stop = min(revision[&#34;stop&#34;], stop) if stop else revision[&#34;stop&#34;]
    return (max_start, min_stop)


class Series:
    &#34;&#34;&#34;
    Combine a pod and a changelog to provide a versioned and
    concurrent management of series.
    &#34;&#34;&#34;

    def __init__(self, label, collection):
        self.collection = collection
        self.schema = collection.schema
        self.pod = collection.pod
        self.changelog = collection.changelog
        self.label = label

    def segments(
        self,
        start=None,
        stop=None,
        before=None,
        closed=&#34;LEFT&#34;,
        from_ci=None,
    ):
        &#34;&#34;&#34;
        Find matching segments
        &#34;&#34;&#34;

        if not from_ci:
            # Find leaf commit
            leaf_rev = self.changelog.leaf(before=before)
            if not leaf_rev:
                return
            from_ci = leaf_rev.commit(self.collection)
        return from_ci.segments(self.label, self.pod, start, stop, closed=closed)

    def period(self, rev):
        &#34;&#34;&#34;
        Return average period (time delta between two tic) of a given revision
        &#34;&#34;&#34;
        start = self.schema.deserialize(rev[&#34;start&#34;])[0]
        stop = self.schema.deserialize(rev[&#34;stop&#34;])[0]
        span = stop - start
        # span is a timedelta64
        span = span.item().total_seconds()
        return span / rev[&#34;len&#34;]

    def interval(self, size=500_000):
        &#34;&#34;&#34;
        Find smallest natural partition that will fit `size` items
        &#34;&#34;&#34;
        schema = self.schema
        head_col = next(iter(schema.idx))
        assert issubdtype(schema[head_col].codec.dt, &#34;datetime64&#34;)

        revisions = self.changelog.log()
        if not revisions:
            return None
        min_period = min(self.period(rev) for rev in revisions)
        target = min_period * size
        return Interval.bisect(target)

    def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
        # Each commit is like a frame. A row in this frame represent a
        # write (aka a segment) and contains one digest per series
        # column + 2*N extra columns that encode start-stop values (N
        # being the number of index columns of the series) + a column
        # containing the series name (like that we can write all the
        # series in one commit)

        frame = Frame(self.schema, frame)

        # Make sure frame is sorted
        # XXX forbid repeated values in index ??
        assert frame.is_sorted(), &#34;Frame is not sorted!&#34;

        # Save segments
        all_dig = []
        arr_length = None
        embedded = {}
        with Pool() as pool:
            for name in self.schema:
                # Cast array &amp; check len
                values = frame[name]
                if arr_length is None:
                    arr_length = len(values)
                elif len(values) != arr_length:
                    raise ValueError(&#34;Length mismatch&#34;)
                digest, embed_data = self._write_col(name, values, pool)
                all_dig.append(digest)
                if embed_data is not None:
                    embedded[digest] = embed_data

        # Build commit info
        start = frame.start() if start is None else start
        stop = frame.stop() if stop is None else stop
        if not isinstance(start, tuple):
            start = (start,)
        if not isinstance(stop, tuple):
            stop = (stop,)

        # Create new digest
        batch = self.collection.batch
        if batch:
            ci_info = (self.label, start, stop, all_dig, len(frame), closed, embedded)
            if isinstance(batch, Batch):
                batch.append(*ci_info)
            else:
                return ci_info
            return
        return self.commit(
            start,
            stop,
            all_dig,
            len(frame),
            root=root,
            closed=closed,
            embedded=embedded,
        )

    def _write_col(self, name, values, pool):
        # Encode content
        arr = self.schema[name].cast(values)
        # Create digest (based on actual array for simple
        # type, based on encoded content for O and U)
        codec = self.schema[name].codec
        data, digest = codec.encode(arr, with_digest=True)

        embedded_data = None
        if len(data) &lt; settings.embed_max_size:  # every small array gets embedded
            # Put small arrays aside
            embedded_data = data
        else:
            folder, filename = hashed_path(digest)
            # XXX move writing in Series.commit and handle situation where the commit gets to large?
            # XXX keep it here for when a batch gets too large ?
            pool.submit(self.pod.cd(folder).write, filename, data)
        return digest, embedded_data

    def update(self, frame):
        frame = Frame(self.schema, frame)
        start, stop = frame.start(), frame.stop()
        idx = tuple(self.schema.idx)
        upd_cols = tuple(c for c in frame if c not in idx)
        read_cols = tuple(c for c in self.schema.columns if c not in idx + upd_cols)
        db_frm = self.frame(start=start, stop=stop, closed=&#34;b&#34;, select=idx + read_cols)
        db_start, db_stop = db_frm.start(), db_frm.stop()
        overlap_frm = frame.islice(db_start, db_stop, &#34;b&#34;)
        head_frm = frame.islice(None, db_start, &#34;l&#34;)
        tail_frm = frame.islice(db_stop, None, &#34;r&#34;)

        # Make sure index matches on overlapping part
        for col in idx:
            if (
                len(db_frm) != len(overlap_frm)
                or (db_frm[col] != overlap_frm[col]).any()
            ):
                raise ValueError(&#34;Update frame is not aligned with existing index&#34;)

        # Update columns
        for col in upd_cols:
            db_frm[col] = overlap_frm[col]

        # Add columns filled with zero-like values in non-overlapping
        # frames
        for frm in (head_frm, tail_frm):
            for col in read_cols:
                frm[col] = self.schema[col].zeroes(len(frm))

        full_frm = Frame.concat(head_frm, db_frm, tail_frm)
        return self.write(full_frm, start, stop, closed=&#34;b&#34;)

    def commit(
        self, start, stop, all_dig, length, root=False, closed=&#34;b&#34;, embedded=None
    ):
        # root force commit on phi
        leaf_rev = None if root else self.changelog.leaf()

        # Combine with last commit
        if leaf_rev:
            leaf_ci = leaf_rev.commit(self.collection)
            new_ci = leaf_ci.update(
                self.label,
                start,
                stop,
                all_dig,
                length,
                closed=closed,
                embedded=embedded,
            )
            # TODO early return if new_ci == leaf_ci
        else:
            new_ci = Commit.one(
                self.schema,
                self.label,
                start,
                stop,
                all_dig,
                length,
                closed=closed,
                embedded=embedded,
            )

        payload = new_ci.encode()
        parent = leaf_rev.child if leaf_rev else phi
        return self.changelog.commit(payload, parents=[parent])

    def delete(self, start, stop, closed=&#34;b&#34;, root=False):
        frm = {k: [] for k in self.schema}
        return self.write(frame=frm, start=start, stop=stop, closed=closed, root=root)

    def __len__(self):
        return len(Query(self, select=list(self.schema.idx)))

    def __bool__(self):
        return self.label in self.collection.ls()

    def paginate(
        self,
        step=settings.page_len,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).paginate(step=step)

    def tail(
        self,
        length,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        &#39;&#39;&#39;
        Return the last `length` values of the series. Optionaly
        pre-filtered between `start` and `stop`.
        &#39;&#39;&#39;
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).tail(length)

    def frame(
        self,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).frame()

    def df(
        self,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).df()


class Query:
    def __init__(
        self,
        series,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
        from_ci=None,
    ):
        self.series = series
        self.start = self.series.schema.deserialize(start)
        self.stop = self.series.schema.deserialize(stop)
        self.closed = Closed.cast(closed)
        self.limit = limit
        self.offset = offset
        self.select = select
        self.before = before
        self.from_ci = from_ci

    def segments(self):
        segments = self.series.segments(
            start=self.start,
            stop=self.stop,
            before=self.before,
            closed=self.closed,
            from_ci=self.from_ci,
        )
        return segments

    def __len__(self):
        return sum(len(s) for s in self.segments())

    def frame(self):
        return Frame.from_segments(
            self.series.schema,
            self.segments(),
            limit=self.limit,
            offset=self.offset,
            select=self.select,
        )

    def df(self):
        return self.frame().df()

    def paginate(self, step=settings.page_len):
        if step &lt;= 0:
            raise ValueError(&#34;step argument must be &gt; 0&#34;)
        segments = self.segments()
        select = self.select
        limit = self.limit
        pos = self.offset or 0
        while True:
            lmt = step if limit is None else min(step, limit)
            offset = pos
            frm = Frame.from_segments(
                self.series.schema, segments, limit=lmt, offset=offset, select=select
            )
            if len(frm) == 0:
                return
            if limit is not None:
                limit -= len(frm)
            yield frm
            pos += step

    def tail(self, length):
        if length &lt;= 0:
            raise ValueError(&#34;length argument must be &gt; 0&#34;)
        segments = self.segments()
        select = self.select
        cnt = 0
        res = []

        # Create one frame per segment, starting from the last one.
        for segment in reversed(segments):
            frm = Frame.from_segments(
                self.series.schema, [segment], select=select
            )
            if cnt + len(frm) &gt;= length:
                # Last frame: keep the correct amount of lines
                cut = length - cnt
                res.append(frm.slice(start=-cut))
                break
            # We consume the full frame, append it and increase counter
            res.append(frm)
            cnt += len(frm)

        # Re-order frames and concat
        frm = Frame.concat(*reversed(res))

        if (self.limit, self.offset) != (None, None):
            start = self.offset or 0
            stop = start + (self.limit or 0)
            frm = frm.slice(start, stop)

        return frm


class KVSeries(Series):
    def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
        if root or not (start is None is stop):
            return super().write(frame, start=start, stop=stop, root=root)

        if not isinstance(frame, Frame):
            frame = Frame(self.schema, frame).sorted()

        segments = self.segments(frame.start(), frame.stop(), closed=&#34;BOTH&#34;)
        db_frm = Frame.from_segments(
            self.schema, segments
        )  # Maybe paginate on large results

        if db_frm.empty:
            return super().write(frame, closed=closed)

        if db_frm == frame:
            # Nothing to do
            return

        # Concat both frame and reduce it
        new_frm = Frame.concat(frame, db_frm)
        reduce_kw = {c: c for c in self.schema.idx}
        non_idx = [c for c in self.schema if c not in self.schema.idx]
        reduce_kw.update({c: f&#34;(first self.{c})&#34; for c in non_idx})
        new_frm = new_frm.reduce(**reduce_kw)
        return super().write(new_frm)  # XXX pass closed ?

    def delete(self, *keys):
        # XXX we have 4 delete method (on series, kvseries, collection
        # and repo), we should get rid of some

        # Create a frame with all the existing keys contained
        # between max and min of keys
        if not keys:
            return

        # XXX use changelog pack ?
        start, stop = min(keys), max(keys)
        frm = self.frame(start, stop, closed=&#34;BOTH&#34;)
        # Keep only keys not given as argument
        # FIXME use frame.mask to filter it
        items = [(k, s) for k, s in zip(frm[&#34;label&#34;], frm[&#34;meta&#34;]) if k not in keys]
        if len(items) == 0:
            new_frm = self.schema.cast()
        else:
            keep_keys, keep_meta = zip(*items)
            new_frm = {
                &#34;label&#34;: keep_keys,
                &#34;meta&#34;: keep_meta,
            }

        # Write result to db
        revs = self.write(new_frm, start=start, stop=stop)
        return revs

    # def delete(self, *keys):
    #     if not keys:
    #         return
    #     frm = self.frame()
    #     mask = &#39;(logical_not (isin self.label {}))&#39;.format(
    #         &#39; &#39;.join(f&#39;&#34;{k}&#34;&#39; for k in keys)
    #     )
    #     new_frm = frm.mask(mask)
    #     self.write(new_frm, start=frm.start(), stop=frm.stop())</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="lakota.series.KVSeries"><code class="flex name class">
<span>class <span class="ident">KVSeries</span></span>
<span>(</span><span>label, collection)</span>
</code></dt>
<dd>
<div class="desc"><p>Combine a pod and a changelog to provide a versioned and
concurrent management of series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KVSeries(Series):
    def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
        if root or not (start is None is stop):
            return super().write(frame, start=start, stop=stop, root=root)

        if not isinstance(frame, Frame):
            frame = Frame(self.schema, frame).sorted()

        segments = self.segments(frame.start(), frame.stop(), closed=&#34;BOTH&#34;)
        db_frm = Frame.from_segments(
            self.schema, segments
        )  # Maybe paginate on large results

        if db_frm.empty:
            return super().write(frame, closed=closed)

        if db_frm == frame:
            # Nothing to do
            return

        # Concat both frame and reduce it
        new_frm = Frame.concat(frame, db_frm)
        reduce_kw = {c: c for c in self.schema.idx}
        non_idx = [c for c in self.schema if c not in self.schema.idx]
        reduce_kw.update({c: f&#34;(first self.{c})&#34; for c in non_idx})
        new_frm = new_frm.reduce(**reduce_kw)
        return super().write(new_frm)  # XXX pass closed ?

    def delete(self, *keys):
        # XXX we have 4 delete method (on series, kvseries, collection
        # and repo), we should get rid of some

        # Create a frame with all the existing keys contained
        # between max and min of keys
        if not keys:
            return

        # XXX use changelog pack ?
        start, stop = min(keys), max(keys)
        frm = self.frame(start, stop, closed=&#34;BOTH&#34;)
        # Keep only keys not given as argument
        # FIXME use frame.mask to filter it
        items = [(k, s) for k, s in zip(frm[&#34;label&#34;], frm[&#34;meta&#34;]) if k not in keys]
        if len(items) == 0:
            new_frm = self.schema.cast()
        else:
            keep_keys, keep_meta = zip(*items)
            new_frm = {
                &#34;label&#34;: keep_keys,
                &#34;meta&#34;: keep_meta,
            }

        # Write result to db
        revs = self.write(new_frm, start=start, stop=stop)
        return revs

    # def delete(self, *keys):
    #     if not keys:
    #         return
    #     frm = self.frame()
    #     mask = &#39;(logical_not (isin self.label {}))&#39;.format(
    #         &#39; &#39;.join(f&#39;&#34;{k}&#34;&#39; for k in keys)
    #     )
    #     new_frm = frm.mask(mask)
    #     self.write(new_frm, start=frm.start(), stop=frm.stop())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="lakota.series.Series" href="#lakota.series.Series">Series</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="lakota.series.KVSeries.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, *keys)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete(self, *keys):
    # XXX we have 4 delete method (on series, kvseries, collection
    # and repo), we should get rid of some

    # Create a frame with all the existing keys contained
    # between max and min of keys
    if not keys:
        return

    # XXX use changelog pack ?
    start, stop = min(keys), max(keys)
    frm = self.frame(start, stop, closed=&#34;BOTH&#34;)
    # Keep only keys not given as argument
    # FIXME use frame.mask to filter it
    items = [(k, s) for k, s in zip(frm[&#34;label&#34;], frm[&#34;meta&#34;]) if k not in keys]
    if len(items) == 0:
        new_frm = self.schema.cast()
    else:
        keep_keys, keep_meta = zip(*items)
        new_frm = {
            &#34;label&#34;: keep_keys,
            &#34;meta&#34;: keep_meta,
        }

    # Write result to db
    revs = self.write(new_frm, start=start, stop=stop)
    return revs</code></pre>
</details>
</dd>
<dt id="lakota.series.KVSeries.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, frame, start=None, stop=None, closed='b', root=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
    if root or not (start is None is stop):
        return super().write(frame, start=start, stop=stop, root=root)

    if not isinstance(frame, Frame):
        frame = Frame(self.schema, frame).sorted()

    segments = self.segments(frame.start(), frame.stop(), closed=&#34;BOTH&#34;)
    db_frm = Frame.from_segments(
        self.schema, segments
    )  # Maybe paginate on large results

    if db_frm.empty:
        return super().write(frame, closed=closed)

    if db_frm == frame:
        # Nothing to do
        return

    # Concat both frame and reduce it
    new_frm = Frame.concat(frame, db_frm)
    reduce_kw = {c: c for c in self.schema.idx}
    non_idx = [c for c in self.schema if c not in self.schema.idx]
    reduce_kw.update({c: f&#34;(first self.{c})&#34; for c in non_idx})
    new_frm = new_frm.reduce(**reduce_kw)
    return super().write(new_frm)  # XXX pass closed ?</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="lakota.series.Series" href="#lakota.series.Series">Series</a></b></code>:
<ul class="hlist">
<li><code><a title="lakota.series.Series.interval" href="#lakota.series.Series.interval">interval</a></code></li>
<li><code><a title="lakota.series.Series.period" href="#lakota.series.Series.period">period</a></code></li>
<li><code><a title="lakota.series.Series.segments" href="#lakota.series.Series.segments">segments</a></code></li>
<li><code><a title="lakota.series.Series.tail" href="#lakota.series.Series.tail">tail</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="lakota.series.Series"><code class="flex name class">
<span>class <span class="ident">Series</span></span>
<span>(</span><span>label, collection)</span>
</code></dt>
<dd>
<div class="desc"><p>Combine a pod and a changelog to provide a versioned and
concurrent management of series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Series:
    &#34;&#34;&#34;
    Combine a pod and a changelog to provide a versioned and
    concurrent management of series.
    &#34;&#34;&#34;

    def __init__(self, label, collection):
        self.collection = collection
        self.schema = collection.schema
        self.pod = collection.pod
        self.changelog = collection.changelog
        self.label = label

    def segments(
        self,
        start=None,
        stop=None,
        before=None,
        closed=&#34;LEFT&#34;,
        from_ci=None,
    ):
        &#34;&#34;&#34;
        Find matching segments
        &#34;&#34;&#34;

        if not from_ci:
            # Find leaf commit
            leaf_rev = self.changelog.leaf(before=before)
            if not leaf_rev:
                return
            from_ci = leaf_rev.commit(self.collection)
        return from_ci.segments(self.label, self.pod, start, stop, closed=closed)

    def period(self, rev):
        &#34;&#34;&#34;
        Return average period (time delta between two tic) of a given revision
        &#34;&#34;&#34;
        start = self.schema.deserialize(rev[&#34;start&#34;])[0]
        stop = self.schema.deserialize(rev[&#34;stop&#34;])[0]
        span = stop - start
        # span is a timedelta64
        span = span.item().total_seconds()
        return span / rev[&#34;len&#34;]

    def interval(self, size=500_000):
        &#34;&#34;&#34;
        Find smallest natural partition that will fit `size` items
        &#34;&#34;&#34;
        schema = self.schema
        head_col = next(iter(schema.idx))
        assert issubdtype(schema[head_col].codec.dt, &#34;datetime64&#34;)

        revisions = self.changelog.log()
        if not revisions:
            return None
        min_period = min(self.period(rev) for rev in revisions)
        target = min_period * size
        return Interval.bisect(target)

    def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
        # Each commit is like a frame. A row in this frame represent a
        # write (aka a segment) and contains one digest per series
        # column + 2*N extra columns that encode start-stop values (N
        # being the number of index columns of the series) + a column
        # containing the series name (like that we can write all the
        # series in one commit)

        frame = Frame(self.schema, frame)

        # Make sure frame is sorted
        # XXX forbid repeated values in index ??
        assert frame.is_sorted(), &#34;Frame is not sorted!&#34;

        # Save segments
        all_dig = []
        arr_length = None
        embedded = {}
        with Pool() as pool:
            for name in self.schema:
                # Cast array &amp; check len
                values = frame[name]
                if arr_length is None:
                    arr_length = len(values)
                elif len(values) != arr_length:
                    raise ValueError(&#34;Length mismatch&#34;)
                digest, embed_data = self._write_col(name, values, pool)
                all_dig.append(digest)
                if embed_data is not None:
                    embedded[digest] = embed_data

        # Build commit info
        start = frame.start() if start is None else start
        stop = frame.stop() if stop is None else stop
        if not isinstance(start, tuple):
            start = (start,)
        if not isinstance(stop, tuple):
            stop = (stop,)

        # Create new digest
        batch = self.collection.batch
        if batch:
            ci_info = (self.label, start, stop, all_dig, len(frame), closed, embedded)
            if isinstance(batch, Batch):
                batch.append(*ci_info)
            else:
                return ci_info
            return
        return self.commit(
            start,
            stop,
            all_dig,
            len(frame),
            root=root,
            closed=closed,
            embedded=embedded,
        )

    def _write_col(self, name, values, pool):
        # Encode content
        arr = self.schema[name].cast(values)
        # Create digest (based on actual array for simple
        # type, based on encoded content for O and U)
        codec = self.schema[name].codec
        data, digest = codec.encode(arr, with_digest=True)

        embedded_data = None
        if len(data) &lt; settings.embed_max_size:  # every small array gets embedded
            # Put small arrays aside
            embedded_data = data
        else:
            folder, filename = hashed_path(digest)
            # XXX move writing in Series.commit and handle situation where the commit gets to large?
            # XXX keep it here for when a batch gets too large ?
            pool.submit(self.pod.cd(folder).write, filename, data)
        return digest, embedded_data

    def update(self, frame):
        frame = Frame(self.schema, frame)
        start, stop = frame.start(), frame.stop()
        idx = tuple(self.schema.idx)
        upd_cols = tuple(c for c in frame if c not in idx)
        read_cols = tuple(c for c in self.schema.columns if c not in idx + upd_cols)
        db_frm = self.frame(start=start, stop=stop, closed=&#34;b&#34;, select=idx + read_cols)
        db_start, db_stop = db_frm.start(), db_frm.stop()
        overlap_frm = frame.islice(db_start, db_stop, &#34;b&#34;)
        head_frm = frame.islice(None, db_start, &#34;l&#34;)
        tail_frm = frame.islice(db_stop, None, &#34;r&#34;)

        # Make sure index matches on overlapping part
        for col in idx:
            if (
                len(db_frm) != len(overlap_frm)
                or (db_frm[col] != overlap_frm[col]).any()
            ):
                raise ValueError(&#34;Update frame is not aligned with existing index&#34;)

        # Update columns
        for col in upd_cols:
            db_frm[col] = overlap_frm[col]

        # Add columns filled with zero-like values in non-overlapping
        # frames
        for frm in (head_frm, tail_frm):
            for col in read_cols:
                frm[col] = self.schema[col].zeroes(len(frm))

        full_frm = Frame.concat(head_frm, db_frm, tail_frm)
        return self.write(full_frm, start, stop, closed=&#34;b&#34;)

    def commit(
        self, start, stop, all_dig, length, root=False, closed=&#34;b&#34;, embedded=None
    ):
        # root force commit on phi
        leaf_rev = None if root else self.changelog.leaf()

        # Combine with last commit
        if leaf_rev:
            leaf_ci = leaf_rev.commit(self.collection)
            new_ci = leaf_ci.update(
                self.label,
                start,
                stop,
                all_dig,
                length,
                closed=closed,
                embedded=embedded,
            )
            # TODO early return if new_ci == leaf_ci
        else:
            new_ci = Commit.one(
                self.schema,
                self.label,
                start,
                stop,
                all_dig,
                length,
                closed=closed,
                embedded=embedded,
            )

        payload = new_ci.encode()
        parent = leaf_rev.child if leaf_rev else phi
        return self.changelog.commit(payload, parents=[parent])

    def delete(self, start, stop, closed=&#34;b&#34;, root=False):
        frm = {k: [] for k in self.schema}
        return self.write(frame=frm, start=start, stop=stop, closed=closed, root=root)

    def __len__(self):
        return len(Query(self, select=list(self.schema.idx)))

    def __bool__(self):
        return self.label in self.collection.ls()

    def paginate(
        self,
        step=settings.page_len,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).paginate(step=step)

    def tail(
        self,
        length,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        &#39;&#39;&#39;
        Return the last `length` values of the series. Optionaly
        pre-filtered between `start` and `stop`.
        &#39;&#39;&#39;
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).tail(length)

    def frame(
        self,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).frame()

    def df(
        self,
        start=None,
        stop=None,
        limit=None,
        offset=None,
        select=None,
        closed=&#34;LEFT&#34;,
        before=None,
    ):
        return Query(
            self,
            start=start,
            stop=stop,
            limit=limit,
            offset=offset,
            before=before,
            closed=closed,
        ).df()</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="lakota.series.KVSeries" href="#lakota.series.KVSeries">KVSeries</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="lakota.series.Series.commit"><code class="name flex">
<span>def <span class="ident">commit</span></span>(<span>self, start, stop, all_dig, length, root=False, closed='b', embedded=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def commit(
    self, start, stop, all_dig, length, root=False, closed=&#34;b&#34;, embedded=None
):
    # root force commit on phi
    leaf_rev = None if root else self.changelog.leaf()

    # Combine with last commit
    if leaf_rev:
        leaf_ci = leaf_rev.commit(self.collection)
        new_ci = leaf_ci.update(
            self.label,
            start,
            stop,
            all_dig,
            length,
            closed=closed,
            embedded=embedded,
        )
        # TODO early return if new_ci == leaf_ci
    else:
        new_ci = Commit.one(
            self.schema,
            self.label,
            start,
            stop,
            all_dig,
            length,
            closed=closed,
            embedded=embedded,
        )

    payload = new_ci.encode()
    parent = leaf_rev.child if leaf_rev else phi
    return self.changelog.commit(payload, parents=[parent])</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, start, stop, closed='b', root=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete(self, start, stop, closed=&#34;b&#34;, root=False):
    frm = {k: [] for k in self.schema}
    return self.write(frame=frm, start=start, stop=stop, closed=closed, root=root)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.df"><code class="name flex">
<span>def <span class="ident">df</span></span>(<span>self, start=None, stop=None, limit=None, offset=None, select=None, closed='LEFT', before=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def df(
    self,
    start=None,
    stop=None,
    limit=None,
    offset=None,
    select=None,
    closed=&#34;LEFT&#34;,
    before=None,
):
    return Query(
        self,
        start=start,
        stop=stop,
        limit=limit,
        offset=offset,
        before=before,
        closed=closed,
    ).df()</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.frame"><code class="name flex">
<span>def <span class="ident">frame</span></span>(<span>self, start=None, stop=None, limit=None, offset=None, select=None, closed='LEFT', before=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def frame(
    self,
    start=None,
    stop=None,
    limit=None,
    offset=None,
    select=None,
    closed=&#34;LEFT&#34;,
    before=None,
):
    return Query(
        self,
        start=start,
        stop=stop,
        limit=limit,
        offset=offset,
        before=before,
        closed=closed,
    ).frame()</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.interval"><code class="name flex">
<span>def <span class="ident">interval</span></span>(<span>self, size=500000)</span>
</code></dt>
<dd>
<div class="desc"><p>Find smallest natural partition that will fit <code>size</code> items</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interval(self, size=500_000):
    &#34;&#34;&#34;
    Find smallest natural partition that will fit `size` items
    &#34;&#34;&#34;
    schema = self.schema
    head_col = next(iter(schema.idx))
    assert issubdtype(schema[head_col].codec.dt, &#34;datetime64&#34;)

    revisions = self.changelog.log()
    if not revisions:
        return None
    min_period = min(self.period(rev) for rev in revisions)
    target = min_period * size
    return Interval.bisect(target)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.paginate"><code class="name flex">
<span>def <span class="ident">paginate</span></span>(<span>self, step=500000, start=None, stop=None, limit=None, offset=None, select=None, closed='LEFT', before=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def paginate(
    self,
    step=settings.page_len,
    start=None,
    stop=None,
    limit=None,
    offset=None,
    select=None,
    closed=&#34;LEFT&#34;,
    before=None,
):
    return Query(
        self,
        start=start,
        stop=stop,
        limit=limit,
        offset=offset,
        before=before,
        closed=closed,
    ).paginate(step=step)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.period"><code class="name flex">
<span>def <span class="ident">period</span></span>(<span>self, rev)</span>
</code></dt>
<dd>
<div class="desc"><p>Return average period (time delta between two tic) of a given revision</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def period(self, rev):
    &#34;&#34;&#34;
    Return average period (time delta between two tic) of a given revision
    &#34;&#34;&#34;
    start = self.schema.deserialize(rev[&#34;start&#34;])[0]
    stop = self.schema.deserialize(rev[&#34;stop&#34;])[0]
    span = stop - start
    # span is a timedelta64
    span = span.item().total_seconds()
    return span / rev[&#34;len&#34;]</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.segments"><code class="name flex">
<span>def <span class="ident">segments</span></span>(<span>self, start=None, stop=None, before=None, closed='LEFT', from_ci=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Find matching segments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def segments(
    self,
    start=None,
    stop=None,
    before=None,
    closed=&#34;LEFT&#34;,
    from_ci=None,
):
    &#34;&#34;&#34;
    Find matching segments
    &#34;&#34;&#34;

    if not from_ci:
        # Find leaf commit
        leaf_rev = self.changelog.leaf(before=before)
        if not leaf_rev:
            return
        from_ci = leaf_rev.commit(self.collection)
    return from_ci.segments(self.label, self.pod, start, stop, closed=closed)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.tail"><code class="name flex">
<span>def <span class="ident">tail</span></span>(<span>self, length, start=None, stop=None, limit=None, offset=None, select=None, closed='LEFT', before=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the last <code>length</code> values of the series. Optionaly
pre-filtered between <code>start</code> and <code>stop</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tail(
    self,
    length,
    start=None,
    stop=None,
    limit=None,
    offset=None,
    select=None,
    closed=&#34;LEFT&#34;,
    before=None,
):
    &#39;&#39;&#39;
    Return the last `length` values of the series. Optionaly
    pre-filtered between `start` and `stop`.
    &#39;&#39;&#39;
    return Query(
        self,
        start=start,
        stop=stop,
        limit=limit,
        offset=offset,
        before=before,
        closed=closed,
    ).tail(length)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, frame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self, frame):
    frame = Frame(self.schema, frame)
    start, stop = frame.start(), frame.stop()
    idx = tuple(self.schema.idx)
    upd_cols = tuple(c for c in frame if c not in idx)
    read_cols = tuple(c for c in self.schema.columns if c not in idx + upd_cols)
    db_frm = self.frame(start=start, stop=stop, closed=&#34;b&#34;, select=idx + read_cols)
    db_start, db_stop = db_frm.start(), db_frm.stop()
    overlap_frm = frame.islice(db_start, db_stop, &#34;b&#34;)
    head_frm = frame.islice(None, db_start, &#34;l&#34;)
    tail_frm = frame.islice(db_stop, None, &#34;r&#34;)

    # Make sure index matches on overlapping part
    for col in idx:
        if (
            len(db_frm) != len(overlap_frm)
            or (db_frm[col] != overlap_frm[col]).any()
        ):
            raise ValueError(&#34;Update frame is not aligned with existing index&#34;)

    # Update columns
    for col in upd_cols:
        db_frm[col] = overlap_frm[col]

    # Add columns filled with zero-like values in non-overlapping
    # frames
    for frm in (head_frm, tail_frm):
        for col in read_cols:
            frm[col] = self.schema[col].zeroes(len(frm))

    full_frm = Frame.concat(head_frm, db_frm, tail_frm)
    return self.write(full_frm, start, stop, closed=&#34;b&#34;)</code></pre>
</details>
</dd>
<dt id="lakota.series.Series.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, frame, start=None, stop=None, closed='b', root=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self, frame, start=None, stop=None, closed=&#34;b&#34;, root=False):
    # Each commit is like a frame. A row in this frame represent a
    # write (aka a segment) and contains one digest per series
    # column + 2*N extra columns that encode start-stop values (N
    # being the number of index columns of the series) + a column
    # containing the series name (like that we can write all the
    # series in one commit)

    frame = Frame(self.schema, frame)

    # Make sure frame is sorted
    # XXX forbid repeated values in index ??
    assert frame.is_sorted(), &#34;Frame is not sorted!&#34;

    # Save segments
    all_dig = []
    arr_length = None
    embedded = {}
    with Pool() as pool:
        for name in self.schema:
            # Cast array &amp; check len
            values = frame[name]
            if arr_length is None:
                arr_length = len(values)
            elif len(values) != arr_length:
                raise ValueError(&#34;Length mismatch&#34;)
            digest, embed_data = self._write_col(name, values, pool)
            all_dig.append(digest)
            if embed_data is not None:
                embedded[digest] = embed_data

    # Build commit info
    start = frame.start() if start is None else start
    stop = frame.stop() if stop is None else stop
    if not isinstance(start, tuple):
        start = (start,)
    if not isinstance(stop, tuple):
        stop = (stop,)

    # Create new digest
    batch = self.collection.batch
    if batch:
        ci_info = (self.label, start, stop, all_dig, len(frame), closed, embedded)
        if isinstance(batch, Batch):
            batch.append(*ci_info)
        else:
            return ci_info
        return
    return self.commit(
        start,
        stop,
        all_dig,
        len(frame),
        root=root,
        closed=closed,
        embedded=embedded,
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lakota" href="index.html">lakota</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="lakota.series.KVSeries" href="#lakota.series.KVSeries">KVSeries</a></code></h4>
<ul class="">
<li><code><a title="lakota.series.KVSeries.delete" href="#lakota.series.KVSeries.delete">delete</a></code></li>
<li><code><a title="lakota.series.KVSeries.write" href="#lakota.series.KVSeries.write">write</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="lakota.series.Series" href="#lakota.series.Series">Series</a></code></h4>
<ul class="two-column">
<li><code><a title="lakota.series.Series.commit" href="#lakota.series.Series.commit">commit</a></code></li>
<li><code><a title="lakota.series.Series.delete" href="#lakota.series.Series.delete">delete</a></code></li>
<li><code><a title="lakota.series.Series.df" href="#lakota.series.Series.df">df</a></code></li>
<li><code><a title="lakota.series.Series.frame" href="#lakota.series.Series.frame">frame</a></code></li>
<li><code><a title="lakota.series.Series.interval" href="#lakota.series.Series.interval">interval</a></code></li>
<li><code><a title="lakota.series.Series.paginate" href="#lakota.series.Series.paginate">paginate</a></code></li>
<li><code><a title="lakota.series.Series.period" href="#lakota.series.Series.period">period</a></code></li>
<li><code><a title="lakota.series.Series.segments" href="#lakota.series.Series.segments">segments</a></code></li>
<li><code><a title="lakota.series.Series.tail" href="#lakota.series.Series.tail">tail</a></code></li>
<li><code><a title="lakota.series.Series.update" href="#lakota.series.Series.update">update</a></code></li>
<li><code><a title="lakota.series.Series.write" href="#lakota.series.Series.write">write</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>