<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>lakota.collection API documentation</title>
<meta name="description" content="Read and Writes Series â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lakota.collection</code></h1>
</header>
<section id="section-intro">
<h2 id="read-and-writes-series">Read and Writes Series</h2>
<p>A collection is instantiated from a <code><a title="lakota.repo.Repo" href="repo.html#lakota.repo.Repo">Repo</a></code> object (see <code><a title="lakota.repo" href="repo.html">lakota.repo</a></code>):</p>
<pre><code class="language-python">clct = repo / 'my_collection'
</code></pre>
<p>Series instantiation</p>
<pre><code class="language-python">all_series = clct.ls()

my_series = clct.series('my_series')
# or
my_series = clct.series / 'my_series'
</code></pre>
<p>See <code><a title="lakota.series" href="series.html">lakota.series</a></code> on how to use <code><a title="lakota.series.Series" href="series.html#lakota.series.Series">Series</a></code>.</p>
<p>The <code><a title="lakota.collection.Collection.multi" href="#lakota.collection.Collection.multi">Collection.multi()</a></code> method returns a contect manager that will provide atomic
(and faster) writes across several series</p>
<pre><code class="language-python">with clct.multi():
    for label, df in ...:
        series = clct / label
        series.write(df)
</code></pre>
<h2 id="concurrent-writes-and-synchronization">Concurrent writes and synchronization</h2>
<p>Collections can also be pushed/pulled and merged.</p>
<pre><code class="language-python">clct = local_repo / 'my_collection'
remote_clct = remote_repo / 'my_collection'
clct.pull(remote_clct)
clct.merge()
</code></pre>
<p>Squash remove past revisions</p>
<pre><code class="language-python">clct.squash()
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
## Read and Writes Series

A collection is instantiated from a `lakota.repo.Repo` object (see `lakota.repo`):
```python
clct = repo / &#39;my_collection&#39;
```

Series instantiation

```python
all_series = clct.ls()

my_series = clct.series(&#39;my_series&#39;)
# or
my_series = clct.series / &#39;my_series&#39;
```

See `lakota.series` on how to use `lakota.series.Series`.

The `lakota.collection.Collection.multi` method returns a contect manager that will provide atomic
(and faster) writes across several series
```python
with clct.multi():
    for label, df in ...:
        series = clct / label
        series.write(df)
```

## Concurrent writes and synchronization

Collections can also be pushed/pulled and merged.

```python
clct = local_repo / &#39;my_collection&#39;
remote_clct = remote_repo / &#39;my_collection&#39;
clct.pull(remote_clct)
clct.merge()
```

Squash remove past revisions
```python
clct.squash()
```
&#34;&#34;&#34;

import threading
from collections import defaultdict
from contextlib import contextmanager
from datetime import datetime
from itertools import chain

from .batch import Batch
from .changelog import Changelog
from .commit import Commit
from .series import KVSeries, Series
from .utils import Pool, hashed_path, logger, settings

__all__ = [&#34;Collection&#34;, &#34;Batch&#34;]


class Collection:
    def __init__(self, label, schema, path, repo):
        self.repo = repo
        self.pod = repo.pod
        self.schema = schema
        self.label = label
        self.changelog = Changelog(self.pod / path)
        self._local = threading.local()
        self._local.batch = None

    def series(self, label):
        label = label.strip()
        if len(label) == 0:
            raise ValueError(f&#34;Invalid label&#34;)
        cls = KVSeries if self.schema.kind == &#34;kv&#34; else Series
        return cls(label, self)

    def __truediv__(self, name):
        return self.series(name)

    def __iter__(self):
        return (self.series(n) for n in self.ls())

    def ls(self):
        rev = self.changelog.leaf()
        if rev is None:
            return []
        payload = rev.read()
        ci = Commit.decode(self.schema, payload)
        return sorted(set(ci.label))

    def delete(self, *labels):
        leaf_rev = self.changelog.leaf()
        if not leaf_rev:
            return

        ci = leaf_rev.commit(self)
        ci = ci.delete_labels(labels)
        parent = leaf_rev.child
        payload = ci.encode()
        return self.changelog.commit(payload, parents=[parent])

    def rename(self, from_label, to_label):
        leaf_rev = self.changelog.leaf()
        if not leaf_rev:
            return

        ci = leaf_rev.commit(self)
        ci = ci.rename_label(from_label, to_label)
        parent = leaf_rev.child
        payload = ci.encode()
        return self.changelog.commit(payload, parents=[parent])

    def refresh(self):
        self.changelog.refresh()

    def push(self, remote, *labels):
        return remote.pull(self, *labels)

    def pull(self, remote):
        &#34;&#34;&#34;
        Pull remote series into self
        &#34;&#34;&#34;
        assert isinstance(remote, Collection), &#34;A Collection instance is required&#34;

        local_digs = set(self.digests())
        remote_digs = set(remote.digests())
        sync = lambda path: self.pod.write(path, remote.pod.read(path))
        with Pool() as pool:
            for dig in remote_digs:
                if dig in local_digs:
                    continue
                folder, filename = hashed_path(dig)
                path = folder / filename
                pool.submit(sync, path)

        self.changelog.pull(remote.changelog)

    def merge(self, *heads):
        revisions = self.changelog.log()
        # Corner cases
        if not revisions:
            return []
        if not heads:
            heads = [r for r in revisions if r.is_leaf]

        # We may have multiple revision pointing to the same child
        # (aka a previous commit). No need to merge again.
        if len(set(r.digests.child for r in heads)) &lt; 2:
            return []

        # Reorganise revision as child-&gt;parents dict
        ch2pr = defaultdict(list)
        for r in revisions:
            ch2pr[r.child].append(r)

        # Find common root
        root = None
        first_parents, *other_parents = [
            list(self._find_parents(h, ch2pr)) for h in heads
        ]
        for root in first_parents:
            if all(root in op for op in other_parents):
                break

        # Reify commits, changelog.log is a depth first traversal, so
        # the first head is also the oldest branch.
        first_ci, *other_ci = [h.commit(self) for h in heads]
        root_ci = root.commit(self) if root else []
        # Pile all rows for all other commit into the first one
        self.batch = True
        for ci in other_ci:
            for pos in range(len(ci)):
                row = ci.at(pos)
                # Skip existing rows
                if row in first_ci or row in root_ci:
                    continue

                # Re-apply row
                closed = row[&#34;closed&#34;]
                if closed == &#34;b&#34;:
                    # Closed commit can be applied as-is
                    first_ci = first_ci.update(**row)
                else:
                    # Non-closed: we read and rewrite
                    series = self / row[&#34;label&#34;]
                    frm = series.frame(
                        start=row[&#34;start&#34;], stop=row[&#34;stop&#34;], closed=closed, from_ci=ci
                    )
                    ci_info = series.write(
                        frm
                    )  # since batch is true series simply returns info
                    first_ci = first_ci.update(*ci_info)

        # encode and commit
        payload = first_ci.encode()
        revs = self.changelog.commit(payload, parents=set(h.child for h in heads))
        self.batch = False
        return revs

    @staticmethod
    def _find_parents(rev, ch2pr):
        queue = ch2pr[rev.child][:]
        while queue:
            rev = queue.pop()
            # Append children
            parents = ch2pr[rev.parent]
            queue.extend(parents)
            yield rev

    def squash(self, pack=True, trim=True):
        &#34;&#34;&#34;
        Remove past revisions, collapse history into one or few large
        frames. Returns newly created revisions.

        If `pack` is False, no new revision is created. If set to
        True, the new revisions created are a complete rewrite of the
        collection, the goal being to defragment the multiple arrays
        constituting the different series.

        If `trim` is True, all revisions except the last one are
        removed.  If set to False, the full history is kept. If set to
        a datetime, all the revision older than the given value will be
        deleted, keeping the recent history.
        &#34;&#34;&#34;
        logger.info(&#39;Squash collection &#34;%s&#34;&#39;, self.label)

        # Read existing revisions
        if trim:
            before = trim if isinstance(trim, datetime) else None
            revs = self.changelog.log(before=before)
        else:
            revs = []

        if not pack:
            # Simply remove older commit
            self.changelog.pod.rm_many([r.path for r in revs[:-1]])
            self.changelog.refresh()
            return []

        # Rewrite each series, based on `step` size arrays
        all_labels = self.ls()
        leaf = self.changelog.leaf()
        commit = leaf and leaf.commit(self)
        # TODO run in parallel
        with self.multi() as batch:
            for label in all_labels:
                logger.info(&#39;Squash series &#34;%s/%s&#34;&#39;, self.label, label)
                # Re-write each series. We use _find_squash_start to
                # fast-forward in the series (we bet on the fact that
                # most series are append-only)
                start = self._find_squash_start(commit, label)
                series = self / label
                for frm in series.paginate(start=start, closed=&#34;r&#34;):
                    series.write(frm)

        # Remove old revisions
        to_remove = [r.path for r in revs]
        if not batch.revs:
            # No new revision created, keep the last one
            to_remove = to_remove[:-1]
        self.changelog.pod.rm_many(to_remove)

        self.changelog.refresh()
        return batch.revs

    def _find_squash_start(self, commit, label):
        &#34;&#34;&#34;
        Find the first &#34;small&#34; segment , and return its start values.
        &#34;&#34;&#34;
        rows = list(commit.match(label))
        if (
            len(rows) &lt; 4
        ):  # TODO this should be a param (we should be able to force-squash)
            return rows[-1][&#34;stop&#34;]

        # Define a minimal acceptable len
        total_len = sum(row[&#34;length&#34;] for row in rows)
        threshold = min(settings.page_len, total_len / 4)

        for row in rows[:-1]:
            # Stop at first small row
            if row[&#34;length&#34;] &lt; threshold:
                return row[&#34;start&#34;]
        return rows[-1][&#34;stop&#34;]

    def digests(self):
        for rev in self.changelog.log():
            ci = rev.commit(self)
            digs = set(chain.from_iterable(ci.digest.values()))
            # return only digest not already embedded in the commit
            digs = digs - set(ci.embedded)
            yield from digs

    @contextmanager
    def multi(self, root=None):
        b = Batch(self, root)
        self.batch = b
        yield b
        b.flush()
        self.batch = None

    @property
    def batch(self):
        return self._local.batch

    @batch.setter
    def batch(self, b):
        self._local.batch = b</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="lakota.collection.Batch"><code class="flex name class">
<span>class <span class="ident">Batch</span></span>
<span>(</span><span>collection, root=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Batch:
    def __init__(self, collection, root=False):
        self.collection = collection
        self._ci_info = []
        self.revs = []
        self.root = root

    def append(self, label, start, stop, all_dig, frame_len, embedded):
        self._ci_info.append((label, start, stop, all_dig, frame_len, embedded))

    def extend(self, *other_batches):
        for b in other_batches:
            self._ci_info.extend(b._ci_info)

    def flush(self):
        if len(self._ci_info) == 0:
            return

        changelog = self.collection.changelog
        leaf_rev = None if self.root else changelog.leaf()
        all_ci_info = iter(self._ci_info)

        # Combine with last commit
        if leaf_rev:
            last_ci = leaf_rev.commit(self.collection)
        else:
            label, start, stop, all_dig, length, embedded = next(all_ci_info)
            last_ci = Commit.one(
                self.collection.schema,
                label,
                start,
                stop,
                all_dig,
                length,
                embedded=embedded,
            )
        for label, start, stop, all_dig, length, embedded in all_ci_info:
            last_ci = last_ci.update(
                label, start, stop, all_dig, length, embedded=embedded
            )

        # Save it
        payload = last_ci.encode()
        parent = leaf_rev.child if leaf_rev else phi
        self.revs = self.collection.changelog.commit(payload, parents=[parent])</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="lakota.collection.Batch.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, label, start, stop, all_dig, frame_len, embedded)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, label, start, stop, all_dig, frame_len, embedded):
    self._ci_info.append((label, start, stop, all_dig, frame_len, embedded))</code></pre>
</details>
</dd>
<dt id="lakota.collection.Batch.extend"><code class="name flex">
<span>def <span class="ident">extend</span></span>(<span>self, *other_batches)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extend(self, *other_batches):
    for b in other_batches:
        self._ci_info.extend(b._ci_info)</code></pre>
</details>
</dd>
<dt id="lakota.collection.Batch.flush"><code class="name flex">
<span>def <span class="ident">flush</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flush(self):
    if len(self._ci_info) == 0:
        return

    changelog = self.collection.changelog
    leaf_rev = None if self.root else changelog.leaf()
    all_ci_info = iter(self._ci_info)

    # Combine with last commit
    if leaf_rev:
        last_ci = leaf_rev.commit(self.collection)
    else:
        label, start, stop, all_dig, length, embedded = next(all_ci_info)
        last_ci = Commit.one(
            self.collection.schema,
            label,
            start,
            stop,
            all_dig,
            length,
            embedded=embedded,
        )
    for label, start, stop, all_dig, length, embedded in all_ci_info:
        last_ci = last_ci.update(
            label, start, stop, all_dig, length, embedded=embedded
        )

    # Save it
    payload = last_ci.encode()
    parent = leaf_rev.child if leaf_rev else phi
    self.revs = self.collection.changelog.commit(payload, parents=[parent])</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="lakota.collection.Collection"><code class="flex name class">
<span>class <span class="ident">Collection</span></span>
<span>(</span><span>label, schema, path, repo)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Collection:
    def __init__(self, label, schema, path, repo):
        self.repo = repo
        self.pod = repo.pod
        self.schema = schema
        self.label = label
        self.changelog = Changelog(self.pod / path)
        self._local = threading.local()
        self._local.batch = None

    def series(self, label):
        label = label.strip()
        if len(label) == 0:
            raise ValueError(f&#34;Invalid label&#34;)
        cls = KVSeries if self.schema.kind == &#34;kv&#34; else Series
        return cls(label, self)

    def __truediv__(self, name):
        return self.series(name)

    def __iter__(self):
        return (self.series(n) for n in self.ls())

    def ls(self):
        rev = self.changelog.leaf()
        if rev is None:
            return []
        payload = rev.read()
        ci = Commit.decode(self.schema, payload)
        return sorted(set(ci.label))

    def delete(self, *labels):
        leaf_rev = self.changelog.leaf()
        if not leaf_rev:
            return

        ci = leaf_rev.commit(self)
        ci = ci.delete_labels(labels)
        parent = leaf_rev.child
        payload = ci.encode()
        return self.changelog.commit(payload, parents=[parent])

    def rename(self, from_label, to_label):
        leaf_rev = self.changelog.leaf()
        if not leaf_rev:
            return

        ci = leaf_rev.commit(self)
        ci = ci.rename_label(from_label, to_label)
        parent = leaf_rev.child
        payload = ci.encode()
        return self.changelog.commit(payload, parents=[parent])

    def refresh(self):
        self.changelog.refresh()

    def push(self, remote, *labels):
        return remote.pull(self, *labels)

    def pull(self, remote):
        &#34;&#34;&#34;
        Pull remote series into self
        &#34;&#34;&#34;
        assert isinstance(remote, Collection), &#34;A Collection instance is required&#34;

        local_digs = set(self.digests())
        remote_digs = set(remote.digests())
        sync = lambda path: self.pod.write(path, remote.pod.read(path))
        with Pool() as pool:
            for dig in remote_digs:
                if dig in local_digs:
                    continue
                folder, filename = hashed_path(dig)
                path = folder / filename
                pool.submit(sync, path)

        self.changelog.pull(remote.changelog)

    def merge(self, *heads):
        revisions = self.changelog.log()
        # Corner cases
        if not revisions:
            return []
        if not heads:
            heads = [r for r in revisions if r.is_leaf]

        # We may have multiple revision pointing to the same child
        # (aka a previous commit). No need to merge again.
        if len(set(r.digests.child for r in heads)) &lt; 2:
            return []

        # Reorganise revision as child-&gt;parents dict
        ch2pr = defaultdict(list)
        for r in revisions:
            ch2pr[r.child].append(r)

        # Find common root
        root = None
        first_parents, *other_parents = [
            list(self._find_parents(h, ch2pr)) for h in heads
        ]
        for root in first_parents:
            if all(root in op for op in other_parents):
                break

        # Reify commits, changelog.log is a depth first traversal, so
        # the first head is also the oldest branch.
        first_ci, *other_ci = [h.commit(self) for h in heads]
        root_ci = root.commit(self) if root else []
        # Pile all rows for all other commit into the first one
        self.batch = True
        for ci in other_ci:
            for pos in range(len(ci)):
                row = ci.at(pos)
                # Skip existing rows
                if row in first_ci or row in root_ci:
                    continue

                # Re-apply row
                closed = row[&#34;closed&#34;]
                if closed == &#34;b&#34;:
                    # Closed commit can be applied as-is
                    first_ci = first_ci.update(**row)
                else:
                    # Non-closed: we read and rewrite
                    series = self / row[&#34;label&#34;]
                    frm = series.frame(
                        start=row[&#34;start&#34;], stop=row[&#34;stop&#34;], closed=closed, from_ci=ci
                    )
                    ci_info = series.write(
                        frm
                    )  # since batch is true series simply returns info
                    first_ci = first_ci.update(*ci_info)

        # encode and commit
        payload = first_ci.encode()
        revs = self.changelog.commit(payload, parents=set(h.child for h in heads))
        self.batch = False
        return revs

    @staticmethod
    def _find_parents(rev, ch2pr):
        queue = ch2pr[rev.child][:]
        while queue:
            rev = queue.pop()
            # Append children
            parents = ch2pr[rev.parent]
            queue.extend(parents)
            yield rev

    def squash(self, pack=True, trim=True):
        &#34;&#34;&#34;
        Remove past revisions, collapse history into one or few large
        frames. Returns newly created revisions.

        If `pack` is False, no new revision is created. If set to
        True, the new revisions created are a complete rewrite of the
        collection, the goal being to defragment the multiple arrays
        constituting the different series.

        If `trim` is True, all revisions except the last one are
        removed.  If set to False, the full history is kept. If set to
        a datetime, all the revision older than the given value will be
        deleted, keeping the recent history.
        &#34;&#34;&#34;
        logger.info(&#39;Squash collection &#34;%s&#34;&#39;, self.label)

        # Read existing revisions
        if trim:
            before = trim if isinstance(trim, datetime) else None
            revs = self.changelog.log(before=before)
        else:
            revs = []

        if not pack:
            # Simply remove older commit
            self.changelog.pod.rm_many([r.path for r in revs[:-1]])
            self.changelog.refresh()
            return []

        # Rewrite each series, based on `step` size arrays
        all_labels = self.ls()
        leaf = self.changelog.leaf()
        commit = leaf and leaf.commit(self)
        # TODO run in parallel
        with self.multi() as batch:
            for label in all_labels:
                logger.info(&#39;Squash series &#34;%s/%s&#34;&#39;, self.label, label)
                # Re-write each series. We use _find_squash_start to
                # fast-forward in the series (we bet on the fact that
                # most series are append-only)
                start = self._find_squash_start(commit, label)
                series = self / label
                for frm in series.paginate(start=start, closed=&#34;r&#34;):
                    series.write(frm)

        # Remove old revisions
        to_remove = [r.path for r in revs]
        if not batch.revs:
            # No new revision created, keep the last one
            to_remove = to_remove[:-1]
        self.changelog.pod.rm_many(to_remove)

        self.changelog.refresh()
        return batch.revs

    def _find_squash_start(self, commit, label):
        &#34;&#34;&#34;
        Find the first &#34;small&#34; segment , and return its start values.
        &#34;&#34;&#34;
        rows = list(commit.match(label))
        if (
            len(rows) &lt; 4
        ):  # TODO this should be a param (we should be able to force-squash)
            return rows[-1][&#34;stop&#34;]

        # Define a minimal acceptable len
        total_len = sum(row[&#34;length&#34;] for row in rows)
        threshold = min(settings.page_len, total_len / 4)

        for row in rows[:-1]:
            # Stop at first small row
            if row[&#34;length&#34;] &lt; threshold:
                return row[&#34;start&#34;]
        return rows[-1][&#34;stop&#34;]

    def digests(self):
        for rev in self.changelog.log():
            ci = rev.commit(self)
            digs = set(chain.from_iterable(ci.digest.values()))
            # return only digest not already embedded in the commit
            digs = digs - set(ci.embedded)
            yield from digs

    @contextmanager
    def multi(self, root=None):
        b = Batch(self, root)
        self.batch = b
        yield b
        b.flush()
        self.batch = None

    @property
    def batch(self):
        return self._local.batch

    @batch.setter
    def batch(self, b):
        self._local.batch = b</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="lakota.collection.Collection.batch"><code class="name">var <span class="ident">batch</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def batch(self):
    return self._local.batch</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="lakota.collection.Collection.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, *labels)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete(self, *labels):
    leaf_rev = self.changelog.leaf()
    if not leaf_rev:
        return

    ci = leaf_rev.commit(self)
    ci = ci.delete_labels(labels)
    parent = leaf_rev.child
    payload = ci.encode()
    return self.changelog.commit(payload, parents=[parent])</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.digests"><code class="name flex">
<span>def <span class="ident">digests</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def digests(self):
    for rev in self.changelog.log():
        ci = rev.commit(self)
        digs = set(chain.from_iterable(ci.digest.values()))
        # return only digest not already embedded in the commit
        digs = digs - set(ci.embedded)
        yield from digs</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.ls"><code class="name flex">
<span>def <span class="ident">ls</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ls(self):
    rev = self.changelog.leaf()
    if rev is None:
        return []
    payload = rev.read()
    ci = Commit.decode(self.schema, payload)
    return sorted(set(ci.label))</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.merge"><code class="name flex">
<span>def <span class="ident">merge</span></span>(<span>self, *heads)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge(self, *heads):
    revisions = self.changelog.log()
    # Corner cases
    if not revisions:
        return []
    if not heads:
        heads = [r for r in revisions if r.is_leaf]

    # We may have multiple revision pointing to the same child
    # (aka a previous commit). No need to merge again.
    if len(set(r.digests.child for r in heads)) &lt; 2:
        return []

    # Reorganise revision as child-&gt;parents dict
    ch2pr = defaultdict(list)
    for r in revisions:
        ch2pr[r.child].append(r)

    # Find common root
    root = None
    first_parents, *other_parents = [
        list(self._find_parents(h, ch2pr)) for h in heads
    ]
    for root in first_parents:
        if all(root in op for op in other_parents):
            break

    # Reify commits, changelog.log is a depth first traversal, so
    # the first head is also the oldest branch.
    first_ci, *other_ci = [h.commit(self) for h in heads]
    root_ci = root.commit(self) if root else []
    # Pile all rows for all other commit into the first one
    self.batch = True
    for ci in other_ci:
        for pos in range(len(ci)):
            row = ci.at(pos)
            # Skip existing rows
            if row in first_ci or row in root_ci:
                continue

            # Re-apply row
            closed = row[&#34;closed&#34;]
            if closed == &#34;b&#34;:
                # Closed commit can be applied as-is
                first_ci = first_ci.update(**row)
            else:
                # Non-closed: we read and rewrite
                series = self / row[&#34;label&#34;]
                frm = series.frame(
                    start=row[&#34;start&#34;], stop=row[&#34;stop&#34;], closed=closed, from_ci=ci
                )
                ci_info = series.write(
                    frm
                )  # since batch is true series simply returns info
                first_ci = first_ci.update(*ci_info)

    # encode and commit
    payload = first_ci.encode()
    revs = self.changelog.commit(payload, parents=set(h.child for h in heads))
    self.batch = False
    return revs</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.multi"><code class="name flex">
<span>def <span class="ident">multi</span></span>(<span>self, root=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def multi(self, root=None):
    b = Batch(self, root)
    self.batch = b
    yield b
    b.flush()
    self.batch = None</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.pull"><code class="name flex">
<span>def <span class="ident">pull</span></span>(<span>self, remote)</span>
</code></dt>
<dd>
<div class="desc"><p>Pull remote series into self</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pull(self, remote):
    &#34;&#34;&#34;
    Pull remote series into self
    &#34;&#34;&#34;
    assert isinstance(remote, Collection), &#34;A Collection instance is required&#34;

    local_digs = set(self.digests())
    remote_digs = set(remote.digests())
    sync = lambda path: self.pod.write(path, remote.pod.read(path))
    with Pool() as pool:
        for dig in remote_digs:
            if dig in local_digs:
                continue
            folder, filename = hashed_path(dig)
            path = folder / filename
            pool.submit(sync, path)

    self.changelog.pull(remote.changelog)</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.push"><code class="name flex">
<span>def <span class="ident">push</span></span>(<span>self, remote, *labels)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def push(self, remote, *labels):
    return remote.pull(self, *labels)</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.refresh"><code class="name flex">
<span>def <span class="ident">refresh</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def refresh(self):
    self.changelog.refresh()</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.rename"><code class="name flex">
<span>def <span class="ident">rename</span></span>(<span>self, from_label, to_label)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rename(self, from_label, to_label):
    leaf_rev = self.changelog.leaf()
    if not leaf_rev:
        return

    ci = leaf_rev.commit(self)
    ci = ci.rename_label(from_label, to_label)
    parent = leaf_rev.child
    payload = ci.encode()
    return self.changelog.commit(payload, parents=[parent])</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.series"><code class="name flex">
<span>def <span class="ident">series</span></span>(<span>self, label)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def series(self, label):
    label = label.strip()
    if len(label) == 0:
        raise ValueError(f&#34;Invalid label&#34;)
    cls = KVSeries if self.schema.kind == &#34;kv&#34; else Series
    return cls(label, self)</code></pre>
</details>
</dd>
<dt id="lakota.collection.Collection.squash"><code class="name flex">
<span>def <span class="ident">squash</span></span>(<span>self, pack=True, trim=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove past revisions, collapse history into one or few large
frames. Returns newly created revisions.</p>
<p>If <code>pack</code> is False, no new revision is created. If set to
True, the new revisions created are a complete rewrite of the
collection, the goal being to defragment the multiple arrays
constituting the different series.</p>
<p>If <code>trim</code> is True, all revisions except the last one are
removed.
If set to False, the full history is kept. If set to
a datetime, all the revision older than the given value will be
deleted, keeping the recent history.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squash(self, pack=True, trim=True):
    &#34;&#34;&#34;
    Remove past revisions, collapse history into one or few large
    frames. Returns newly created revisions.

    If `pack` is False, no new revision is created. If set to
    True, the new revisions created are a complete rewrite of the
    collection, the goal being to defragment the multiple arrays
    constituting the different series.

    If `trim` is True, all revisions except the last one are
    removed.  If set to False, the full history is kept. If set to
    a datetime, all the revision older than the given value will be
    deleted, keeping the recent history.
    &#34;&#34;&#34;
    logger.info(&#39;Squash collection &#34;%s&#34;&#39;, self.label)

    # Read existing revisions
    if trim:
        before = trim if isinstance(trim, datetime) else None
        revs = self.changelog.log(before=before)
    else:
        revs = []

    if not pack:
        # Simply remove older commit
        self.changelog.pod.rm_many([r.path for r in revs[:-1]])
        self.changelog.refresh()
        return []

    # Rewrite each series, based on `step` size arrays
    all_labels = self.ls()
    leaf = self.changelog.leaf()
    commit = leaf and leaf.commit(self)
    # TODO run in parallel
    with self.multi() as batch:
        for label in all_labels:
            logger.info(&#39;Squash series &#34;%s/%s&#34;&#39;, self.label, label)
            # Re-write each series. We use _find_squash_start to
            # fast-forward in the series (we bet on the fact that
            # most series are append-only)
            start = self._find_squash_start(commit, label)
            series = self / label
            for frm in series.paginate(start=start, closed=&#34;r&#34;):
                series.write(frm)

    # Remove old revisions
    to_remove = [r.path for r in revs]
    if not batch.revs:
        # No new revision created, keep the last one
        to_remove = to_remove[:-1]
    self.changelog.pod.rm_many(to_remove)

    self.changelog.refresh()
    return batch.revs</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#read-and-writes-series">Read and Writes Series</a></li>
<li><a href="#concurrent-writes-and-synchronization">Concurrent writes and synchronization</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lakota" href="index.html">lakota</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="lakota.collection.Batch" href="#lakota.collection.Batch">Batch</a></code></h4>
<ul class="">
<li><code><a title="lakota.collection.Batch.append" href="#lakota.collection.Batch.append">append</a></code></li>
<li><code><a title="lakota.collection.Batch.extend" href="#lakota.collection.Batch.extend">extend</a></code></li>
<li><code><a title="lakota.collection.Batch.flush" href="#lakota.collection.Batch.flush">flush</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="lakota.collection.Collection" href="#lakota.collection.Collection">Collection</a></code></h4>
<ul class="two-column">
<li><code><a title="lakota.collection.Collection.batch" href="#lakota.collection.Collection.batch">batch</a></code></li>
<li><code><a title="lakota.collection.Collection.delete" href="#lakota.collection.Collection.delete">delete</a></code></li>
<li><code><a title="lakota.collection.Collection.digests" href="#lakota.collection.Collection.digests">digests</a></code></li>
<li><code><a title="lakota.collection.Collection.ls" href="#lakota.collection.Collection.ls">ls</a></code></li>
<li><code><a title="lakota.collection.Collection.merge" href="#lakota.collection.Collection.merge">merge</a></code></li>
<li><code><a title="lakota.collection.Collection.multi" href="#lakota.collection.Collection.multi">multi</a></code></li>
<li><code><a title="lakota.collection.Collection.pull" href="#lakota.collection.Collection.pull">pull</a></code></li>
<li><code><a title="lakota.collection.Collection.push" href="#lakota.collection.Collection.push">push</a></code></li>
<li><code><a title="lakota.collection.Collection.refresh" href="#lakota.collection.Collection.refresh">refresh</a></code></li>
<li><code><a title="lakota.collection.Collection.rename" href="#lakota.collection.Collection.rename">rename</a></code></li>
<li><code><a title="lakota.collection.Collection.series" href="#lakota.collection.Collection.series">series</a></code></li>
<li><code><a title="lakota.collection.Collection.squash" href="#lakota.collection.Collection.squash">squash</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>